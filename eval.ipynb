{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import data_helpers\n",
    "from data_loader import DataLoader\n",
    "from word_data_processor import WordDataProcessor\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=True\n",
      "BAG_OF_WORD_DATA_FILE=bow.out\n",
      "BATCH_SIZE=64\n",
      "CHECKPOINT_DIR=/root/notebooks/dawoon/runs/1497442275/checkpoints/\n",
      "DEV_DATA_FILE=test-sms_word_vector.csv\n",
      "EVAL_TRAIN=True\n",
      "LOG_DEVICE_PLACEMENT=False\n",
      "TRAIN_DATA_FILE=data-sms_word_vector.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Eval Parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n",
    "# 1496390706 filter_sizes:3,4,5 num_epochs:10\n",
    "# 1496630751 2,3,4 num_epochs: 10\n",
    "# 1496997900 2,3,4 num_epochs:2\n",
    "# 1497262314 2,3,4 num_epochs : 30\n",
    "# 1497442275 2,3,4 num_epochs : 10  l2_reg_lambda : 0.5\n",
    "tf.flags.DEFINE_string(\"checkpoint_dir\", \"/root/notebooks/dawoon/runs/1497442275/checkpoints/\", \"Checkpoint directory from training run\")\n",
    "tf.flags.DEFINE_boolean(\"eval_train\", True, \"Evaluate on all training data\")\n",
    "\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "data_loader = DataLoader(tf.flags, WordDataProcessor())\n",
    "data_loader.define_flags()\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if FLAGS.eval_train:\n",
    "    #x_test, y_test = data_loader.load_data_and_labels()\n",
    "    x_test = np.array([[2,45,1,3,1,43584,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                       ,[1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                       ,[2,1022,1,3,4,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                       ,[2,10,12,3,1,1,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                        ,[2,1,3,1,4197,17,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                      ,[2,3698,1,22396,13875,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                      ,[2,37899,1,42,66993,4197,1,3,43,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "                      ,[2,1,1,1,1,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]])\n",
    "    y_test = [0,0,1,0,1,1,1,1]\n",
    "    #print(\"x_test.shape\", x_test.shape)\n",
    "    #print(\"x_test[0]\", x_test[0])\n",
    "else:\n",
    "    x_test, y_test = data_loader.load_dev_data_and_labels()\n",
    "    print(\"x_test.shape\", x_test.shape)\n",
    "    print(\"x_test[0]\", x_test[0])\n",
    "    print(\"y_test.shape\", y_test.shape)\n",
    "    print(\"y_test[0]\", y_test[0])\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "    print(\"y_test.shape\", y_test.shape)\n",
    "    print(\"y_test[0]\", y_test[0])\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkpoint_dir이 없다면 가장 최근 dir 추출하여 셋팅\n",
    "if FLAGS.checkpoint_dir == \"\":\n",
    "    all_subdirs = [\"./runs/\" + d for d in os.listdir('./runs/.') if os.path.isdir(\"./runs/\" + d)]\n",
    "    latest_subdir = max(all_subdirs, key=os.path.getmtime)\n",
    "    FLAGS.checkpoint_dir = latest_subdir + \"/checkpoints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating...\n",
      "\n",
      "('\\ncheckpoint_file', u'/root/notebooks/dawoon/runs/1497442275/checkpoints/model-28000')\n"
     ]
    }
   ],
   "source": [
    "# Map data into vocabulary\n",
    "# restore_vocab_processor는 이미 전처리 되어서 생략\n",
    "\n",
    "print(\"\\nEvaluating...\\n\")\n",
    "checkpoint_file = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "print (\"\\ncheckpoint_file\", checkpoint_file)\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        # Load the saved meta graph and restore variables\n",
    "        saver = tf.train.import_meta_graph(\"{}.meta\".format(checkpoint_file))\n",
    "        saver.restore(sess, checkpoint_file)\n",
    "\n",
    "        # Get the placeholders from the graph by name\n",
    "        input_x = graph.get_operation_by_name(\"input_x\").outputs[0]\n",
    "        # input_y = graph.get_operation_by_name(\"input_y\").outputs[0]\n",
    "        #operations = graph.get_operations()\n",
    "        #print(\"operations\", operations)\n",
    "        \n",
    "        # sms_cnn.py에 오타가 있었음 dropout_keep_prob -> dropout_keep_porb\n",
    "        dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_prob\").outputs[0] \n",
    "        #dropout_keep_prob = graph.get_operation_by_name(\"dropout_keep_porb\").outputs[0]\n",
    "        \n",
    "\n",
    "        # Tensors we want to evaluate\n",
    "        #embedding/output/predictions 또 인덴트 오타가 있었음ㅠ \n",
    "        #predictions = graph.get_operation_by_name(\"embedding/output/predictions\").outputs[0]\n",
    "        predictions = graph.get_operation_by_name(\"output/predictions\").outputs[0]\n",
    "        \n",
    "        \n",
    "        # Generate batches for one epoch\n",
    "        batches = data_helpers.batch_iter(list(x_test), FLAGS.batch_size, 1, shuffle=False)\n",
    "\n",
    "        # Collect the predictions here\n",
    "        all_predictions = []\n",
    "\n",
    "        for x_test_batch in batches:\n",
    "            batch_predictions = sess.run(predictions, {input_x: x_test_batch, dropout_keep_prob: 1.0})\n",
    "            all_predictions = np.concatenate([all_predictions, batch_predictions])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples: 8\n",
      "Accuracy: 0.75\n",
      "[Web발신]\n",
      "KB국민카드\n",
      "UNKNOWN\n",
      "DATETIME\n",
      "UNKNOWN\n",
      "오류\n",
      "\n",
      "[Web발신]\n",
      "UNKNOWN\n",
      "UNKNOWN\n",
      "UNKNOWN\n",
      "UNKNOWN\n",
      "누적_MONEY_WON\n",
      "\n",
      "('y_test', [0, 0, 1, 0, 1, 1, 1, 1])\n",
      "('all_predictions', array([ 1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.]))\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy if y_test is defined\n",
    "if y_test is not None:\n",
    "    correct_predictions = float(sum(all_predictions == y_test ))\n",
    "    correct_predictions_of1 = float(sum(all_predictions == y_test))\n",
    "    print(\"Total number of test examples: {}\".format(len(y_test)))\n",
    "    print(\"Accuracy: {:g}\".format(correct_predictions/float(len(y_test))))\n",
    "\n",
    "    \n",
    "    if FLAGS.eval_train:\n",
    "        for idx, x in enumerate(x_test): \n",
    "            if y_test[idx] != all_predictions[idx]:\n",
    "                for x_word in x:\n",
    "                    if x_word != 0:\n",
    "                        print (data_loader.get_word_by_id(str(x_word)))\n",
    "                print(\"\")\n",
    "        print(\"y_test\", y_test)\n",
    "        print(\"all_predictions\", all_predictions)\n",
    "# Save the evaluation to a csv\n",
    "#class_predictions = data_loader.class_labels(all_predictions.astype(int))\n",
    "#predictions_human_readable = np.column_stack((np.array(x_raw), class_predictions))\n",
    "#out_path = os.path.join(FLAGS.checkpoint_dir, \"../../../\", \"prediction.csv\")\n",
    "#print(\"Saving evaluation to {0}\".format(out_path))\n",
    "#with open(out_path, 'w') as f:\n",
    "    #csv.writer(f).writerows(predictions_human_readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
